{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DenseNet2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohitgarg2411/CNN-architectures-implemetation-in-pytorch/blob/master/DenseNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9CXo1I3fYwJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HAqWihpO5l_",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pHimwlTqDj8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class bottle_neck(nn.Module):\n",
        "  def __init__(self,in_channels,k):\n",
        "    #k=growth rate\n",
        "    super(bottle_neck,self).__init__()\n",
        "    self.bn1=nn.BatchNorm2d(in_channels)\n",
        "    self.conv1=nn.Conv2d(in_channels,4*k,1)\n",
        "    self.bn2=nn.BatchNorm2d(4*k)\n",
        "    self.conv2=nn.Conv2d(4*k,k,3,padding=1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    output=F.relu(self.bn1(x))\n",
        "    output=F.relu(self.bn2(self.conv1(output)))\n",
        "    output=self.conv2(output)\n",
        "    output=torch.cat([x,output],1)\n",
        "    return output\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf2EZqdvrn-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class transition(nn.Module):\n",
        "  def __init__(self,in_channels,out_channels):\n",
        "    super(transition,self).__init__()\n",
        "    self.bn=nn.BatchNorm2d(in_channels)\n",
        "    self.conv1=nn.Conv2d(in_channels,out_channels,1)\n",
        "    self.avgpool=nn.AvgPool2d(2,stride=2)\n",
        "  \n",
        "  def forward(self,x):\n",
        "    output=self.conv1(self.bn(x))\n",
        "    output=self.avgpool(output)\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLySAVhttKzU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " class DenseNet(nn.Module):\n",
        "\n",
        "   def __init__(self,block,nblocks,growth_rate=12,reduction=0.5,num_class=100):\n",
        "     super(DenseNet,self).__init__()\n",
        "     self.growth_rate=growth_rate\n",
        "     inner_channels=2*growth_rate\n",
        "     self.conv1=nn.Conv2d(3,inner_channels,3,padding=1)\n",
        "     self.bn1=nn.BatchNorm2d(inner_channels)\n",
        "     self.features=nn.Sequential()\n",
        "\n",
        "     for i in range(len(nblocks)-1):\n",
        "       self.features.add_module(\"dense_block_layer{}\".format(i),self.make_dense_layers(block,inner_channels,nblocks[i]))\n",
        "       inner_channels+=growth_rate*nblocks[i]\n",
        "       out_channels=int(reduction*inner_channels)\n",
        "       self.features.add_module(\"transition_layer_{}\".format(i), transition(inner_channels, out_channels))\n",
        "       inner_channels=out_channels\n",
        "\n",
        "     self.features.add_module(\"dense_block{}\".format(len(nblocks) - 1), self.make_dense_layers(block, inner_channels, nblocks[len(nblocks)-1]))\n",
        "     inner_channels += growth_rate * nblocks[len(nblocks) - 1]\n",
        "     self.features.add_module('bn', nn.BatchNorm2d(inner_channels))\n",
        "     self.features.add_module('relu', nn.ReLU())\n",
        "     self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "     self.linear = nn.Linear(inner_channels, num_class)\n",
        "\n",
        "   def forward(self, x):\n",
        "        output = self.bn1(self.conv1(x))\n",
        "        output = self.features(output)\n",
        "        output = self.avgpool(output)\n",
        "        #print(output.size()[0])\n",
        "        output = output.view(output.size()[0], -1)\n",
        "        output = self.linear(output)\n",
        "        return output\n",
        "\n",
        "   def make_dense_layers(self, block, in_channels, nblocks):\n",
        "        dense_block = nn.Sequential()\n",
        "        for index in range(nblocks):\n",
        "            dense_block.add_module('bottle_neck_layer_{}'.format(index), block(in_channels, self.growth_rate))\n",
        "            in_channels += self.growth_rate\n",
        "        return dense_block \n",
        "\n",
        "\n",
        "     \n",
        "              \n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPt5SV--LxMn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def group_label(label):\n",
        "\n",
        "    if label<=9 or 35<=label<=44 or 55<=label<=69 or 75<=label<=84:\n",
        "       return 0\n",
        "    elif 10<=label<=14 or 20<=label<=24 or 84<=label<=89:\n",
        "       return 1\n",
        "    elif 15<=label<=19 or 25<=label<=34 or label>=90:\n",
        "       return 2 \n",
        "    elif 45<=label<=54:\n",
        "       return 3\n",
        "    elif 70<=label<=74:\n",
        "       return 4\n",
        "\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEKmd_9uQjLC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loaded_model=DenseNet(bottle_neck,[16,16,16])\n",
        "loaded_model.load_state_dict(torch.load(\"/content/drive/My Drive/rohit/model1.pth\"))\n",
        "loaded_model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvTV2KsO6KvS",
        "colab_type": "code",
        "outputId": "ab86769d-5a47-4da1-8589-6c848675fa2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "\n",
        "transform1 = transforms.Compose(\n",
        "        [transforms.RandomCrop(32,padding=4),\n",
        "         transforms.RandomHorizontalFlip(),\n",
        "         transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        "        )\n",
        "transform2 = transforms.Compose(\n",
        "        [transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        "        )\n",
        "\n",
        "    #Load train and test set:\n",
        "\n",
        "train = torchvision.datasets.CIFAR100(root='/content/drive/My Drive/datasets',train=True,download=True,transform=transform1)\n",
        "trainset = torch.utils.data.DataLoader(train,batch_size=64,shuffle=True)\n",
        "\n",
        "test = torchvision.datasets.CIFAR100(root='/content/drive/My Drive/datasets',train=False,download=True,transform=transform2)\n",
        "testset = torch.utils.data.DataLoader(test,batch_size=64,shuffle=False)\n",
        "    \n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "net = loaded_model\n",
        "net.to(device)\n",
        "costFunc = torch.nn.CrossEntropyLoss()\n",
        "optimizer =  torch.optim.SGD(net.parameters(),lr=0.01,momentum=0.9,nesterov=True,weight_decay=0.0001)\n",
        "scheduler=torch.optim.lr_scheduler.StepLR(optimizer,step_size=25,gamma=0.1)\n",
        "\n",
        "'''for epoch in range(50):\n",
        "        closs = 0\n",
        "        total=0\n",
        "        correctHits=0\n",
        "        for i,batch in enumerate(trainset):\n",
        "            data,output = batch\n",
        "            data,output = data.to(device),output.to(device)\n",
        "            prediction = net(data)\n",
        "            loss = costFunc(prediction,output)\n",
        "            closs = loss.item()\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            #print every 100th time\n",
        "            if i%100 == 0:\n",
        "                print('[%d  %d] loss: %f'% (epoch+1,i+1,closs))\n",
        "            _,prediction = torch.max(prediction.data,1)  #returns max as well as its index\n",
        "            total += output.size(0)\n",
        "            correctHits += (prediction==output).sum().item()\n",
        "        accu=100.0*correctHits/total\n",
        "        for param_group in optimizer.param_groups:\n",
        "            print(\"learning rate= \"+str(param_group['lr']))\n",
        "        print(f'training_accuracy ={accu}')'''\n",
        "        \n",
        "    #test\n",
        "with torch.no_grad():\n",
        "         correctHits=0\n",
        "         total=0\n",
        "         n_class_correct = [0 for i in range(100)]\n",
        "         n_class_samples = [0 for i in range(100)]\n",
        "         for batch_no,batches in enumerate(testset):\n",
        "            data,output = batches\n",
        "            data,output = data.to(device),output.to(device)\n",
        "            prediction = net(data)\n",
        "            _,prediction = torch.max(prediction.data,1)  #returns max as well as its index\n",
        "            total += output.size(0)\n",
        "            correctHits += (prediction==output).sum().item()\n",
        "\n",
        "            for i in range(64 if batch_no!=156 else 16):\n",
        "                  label = output[i]\n",
        "                  pred = prediction[i]\n",
        "                  if (label == pred):\n",
        "                     n_class_correct[label] += 1\n",
        "                  n_class_samples[label] += 1\n",
        "          \n",
        "         accu=100.0*correctHits/total\n",
        "         print(f'testing_accuracy ={accu}')\n",
        "         scheduler.step()\n",
        "\n",
        "\n",
        "n_group_correct = [0 for i in range(5)]\n",
        "n_group_samples = [0 for i in range(5)]\n",
        "for i in range(100):\n",
        "            grp=group_label(i)\n",
        "            n_group_correct[grp]+=n_class_correct[i]\n",
        "            n_group_samples[grp]+=n_class_samples[i]\n",
        "\n",
        "for i in range(5):      \n",
        "           print(n_group_samples[i])\n",
        "           acc=100.0*n_group_correct[i]/n_group_samples[i]\n",
        "           print(f'accuracy for group {i+1} is {acc} %')    \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "cuda\n",
            "testing_accuracy =72.86\n",
            "4500\n",
            "accuracy for group 1 is 73.84444444444445 %\n",
            "1500\n",
            "accuracy for group 2 is 76.4 %\n",
            "2500\n",
            "accuracy for group 3 is 70.88 %\n",
            "1000\n",
            "accuracy for group 4 is 72.7 %\n",
            "500\n",
            "accuracy for group 5 is 63.6 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yztywwUdNMuL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(loaded_model.state_dict(),\"/content/drive/My Drive/rohit/model1.pth\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXfWXEaRq6wf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}